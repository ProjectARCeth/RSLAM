%YAML:1.0

#--------------------------------------------------------------------------------------------
# Camera Parameters. Adjusted at 08_05_2017
#--------------------------------------------------------------------------------------------

# Camera calibration and distortion parameters (OpenCV) 
Camera.fx: 469.822638
Camera.fy: 469.804416
Camera.cx: 398.462515
Camera.cy: 258.476514

Camera.k1: -0.299328
Camera.k2: 0.092340
Camera.p1: 0.000152
Camera.p2: -0.000330

Camera.width: 752
Camera.height: 480

# Camera frames per second 
Camera.fps: 20.0

# stereo baseline times fx
Camera.bf: 51.817399

# Color order of the images (0: BGR, 1: RGB. It is ignored if images are grayscale)
Camera.RGB: 1

# Close/Far threshold. Baseline times.
ThDepth: 35

#--------------------------------------------------------------------------------------------
# Stereo Rectification. Only if you need to pre-rectify the images.
# Camera.fx, .fy, etc must be the same as in LEFT.P
#--------------------------------------------------------------------------------------------
LEFT.height: 480
LEFT.width: 752
LEFT.D: !!opencv-matrix
   rows: 1
   cols: 5
   dt: d
   data: [-0.299328, 0.092340, 0.000152, -0.000330, 0.000000]
LEFT.K: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [469.822638, 0.000000, 398.462515, 0.000000, 469.804416, 258.476514, 0.000000, 0.000000, 1.000000]
LEFT.R:  !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [0.999995, 0.002132, -0.002203, -0.002128, 0.999996, 0.001765, 0.002207, -0.001761, 0.999996]
LEFT.P:  !!opencv-matrix
   rows: 3
   cols: 4
   dt: d
   data: [469.836996, 0.000000, 389.084084, 0.000000, 0.000000, 469.836996, 240.294226, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]

RIGHT.height: 480
RIGHT.width: 752
RIGHT.D: !!opencv-matrix
   rows: 1
   cols: 5
   dt: d
   data: [-0.297329, 0.085599, 0.000420, -0.000612, 0.000000]
RIGHT.K: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [467.453844, 0.000000, 367.705424, 0.000000, 467.469038, 222.064946, 0.000000, 0.000000, 1.000000]
RIGHT.R:  !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [0.999852, 0.000795, -0.017193, -0.000825, 0.999998, -0.001756, 0.017192, 0.001770, 0.999851]
RIGHT.P:  !!opencv-matrix
   rows: 3
   cols: 4
   dt: d
   data: [469.836996, 0.000000, 389.084084, -51.572855, 0.000000, 469.836996, 240.294226, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]

#--------------------------------------------------------------------------------------------
# ORB Parameters
#--------------------------------------------------------------------------------------------

# ORB Extractor: Number of features per image
ORBextractor.nFeatures: 800 # 1200

# ORB Extractor: Scale factor between levels in the scale pyramid    
ORBextractor.scaleFactor: 1.2

# ORB Extractor: Number of levels in the scale pyramid   
ORBextractor.nLevels: 8

# ORB Extractor: Fast threshold
# Image is divided in a grid. At each cell FAST are extracted imposing a minimum response.
# Firstly we impose iniThFAST. If no corners are detected we impose a lower value minThFAST
# You can lower these values if your images have low contrast        
ORBextractor.iniThFAST: 20 # 20
ORBextractor.minThFAST: 5 # 5

#--------------------------------------------------------------------------------------------
# Viewer Parameters
#--------------------------------------------------------------------------------------------
Viewer.KeyFrameSize: 0.7 #0.05
Viewer.KeyFrameLineWidth: 1
Viewer.GraphLineWidth: 0.9
Viewer.PointSize:2
Viewer.CameraSize: 0.7 #0.08
Viewer.CameraLineWidth: 3
Viewer.ViewpointX: 0
Viewer.ViewpointY: -12 #-0.7
Viewer.ViewpointZ: -8 #-1.8
Viewer.ViewpointF: 500 #500


#--------------------------------------------------------------------------------------------
# Tracking Preferences
#--------------------------------------------------------------------------------------------

# Choose initial position of the camera frame.
# 0 identitiy: Default setting, set Twc to identity
# 1 external: Set Twc using external pose measurement
Tracking.InitialPosition: 1

# Choose motion model to be employed for pose prediction
# 0 internal: T_cw(k) = mVelocity(k-1,k-2)*mLastPose(k-2) = (T_cw(k-1)*T_wc(k-2))*T_cw(k-1)
# 1 external: same as above but feed external measurement for estimation mVelocity = T_cw(k-1)*T_wc(k-1)
Tracking.MotionModelSource: 1

# Choose whether system should be reset completely if tracking is lost soon after last new map creation
Tracking.ResetIfLost: 0

# Choose max number of frames until keyframe insertion. Defaults to framesPerSecond if invalid, eg <1
Tracking.MaxNumberFramesBeforeKF: -5

# Choose whether - in the case of lost tracking - pose estimates obtained by velocity model should be set as next valid pose
Tracking.DeadReckoning: 1

# Choose whether an initial guess of the pose should be included as fixed node in the pose optimization
Tracking.PoseOptimizationPrior: 1

# Choose weak tracking threshold. If the best covisible keyframe has less than this number of covisible features
# the relative position will be reinforced with additional edges in the bundle adjustment. Set -1 for no reinforcement.
Tracking.ReinforceWeakTrackingThreshold: 10

# Choose whether the number of extracted features per frame should be adapted according to number of matched points
Tracking.AdaptNFeatures: 0

